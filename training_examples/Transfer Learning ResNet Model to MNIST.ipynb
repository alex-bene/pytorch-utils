{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.autonotebook import trange, tqdm\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from adabound import AdaBound\n",
    "\n",
    "from pytorchUtils.Pipeline import Pipeline\n",
    "from pytorchUtils.models import ResNet\n",
    "from pytorchUtils.models import pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mean and std for the train data in order to normalize our data later\n",
    "trainset      = datasets.MNIST(download=True, train=True, transform=transforms.ToTensor(), root=\"./data\")\n",
    "trainloader   = torch.utils.data.DataLoader(trainset, batch_size=len(trainset), shuffle=False)\n",
    "trainset_mean = next(iter(trainloader))[0].mean(axis=(0, 2, 3))[0]\n",
    "trainset_std  = next(iter(trainloader))[0].std( axis=(0, 2, 3))[0]\n",
    "print(f' Trainset mean value for each channel is: {trainset_mean:.2f}')\n",
    "print(f' Trainset std  value for each channel is: {trainset_std :.2f}')\n",
    "\n",
    "def normalized_tensor_to_image(tt, mean, std):\n",
    "    return np.transpose(tt.detach().clone(), (1, 2, 0))*(std[(None, )*2]) + (mean[(None, )*2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform   = transforms.Compose([transforms.Resize((224, 224)),\n",
    "                                  transforms.ToTensor(),\n",
    "                                  transforms.Lambda(lambda x: x.repeat(3, 1, 1)), #grayscale to RGB\n",
    "                                  transforms.Normalize(trainset_mean, trainset_std)])\n",
    "\n",
    "trainset    = datasets.MNIST('./data', download=True, train=True,  transform=transform)\n",
    "testset     = datasets.MNIST('./data', download=True, train=False, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "testloader  = torch.utils.data.DataLoader(testset,  batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def min_max_scaling(img):\n",
    "    return (img-img.min())/(img.max()-img.min())\n",
    "\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "num_of_images = 60\n",
    "for index in range(1, num_of_images + 1):\n",
    "    plt.subplot(6, 10, index)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(min_max_scaling(np.transpose(images[index], (1, 2, 0))[:, :, 0]), cmap='gray')\n",
    "    plt.title(int(labels[index].cpu()))\n",
    "    plt.subplots_adjust(hspace=0, wspace=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model  = ResNet(pretrained=True, feature_extraction=True, num_classes=10, resnet_type='resnet18')\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss() # loss function -- cross entropy works well for multi-class problems\n",
    "optimizer = AdaBound(model.parameters(), lr=1e-3, final_lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ppln = Pipeline(model, device, optimizer, criterion, trainloader, testloader, testloader, live_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ppln.training(epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ppln.test(model=ppln.best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(ppln.best_model.state_dict(),\n",
    "           os.path.join(os.getcwd(), 'data', f\"MNIST__ResNet18Model__Adabound__{ppln.epochs}_epochs.pth\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
